{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getdata():\n",
    "    import pandas as pd\n",
    "    df = pd.read_pickle('/home/patrick/Documents/Alt Coin Proj/data/newfeat.pkl')\n",
    "    df = df['LTC']\n",
    "    length = len(df)\n",
    "    data = df.drop('up',axis=1)\n",
    "    target = df['up']\n",
    "    data = data.as_matrix()\n",
    "    target = np.asarray(target, dtype=np.int8)\n",
    "    \n",
    "    \n",
    "    N,M = data.shape\n",
    "    \n",
    "    all_X = np.ones((N,M+1))\n",
    "    all_X[:,1:] = data\n",
    "    \n",
    "    num_labels = len(np.unique(target))\n",
    "    all_Y = np.eye(num_labels,dtype=np.int8)[target]\n",
    "    #all_Y = np.array(target,dtype=np.int8)\n",
    "    #all_Y = all_Y.reshape(len(all_Y),)\n",
    "    \n",
    "    trainx = all_X[2000:7000]\n",
    "    testx = all_X[7001:]\n",
    "    \n",
    "    trainy = all_Y[2000:7000]\n",
    "    testy = all_Y[7001:]\n",
    "    \n",
    "    \n",
    "    return trainx,testx,trainy,testy,length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a new log file\n",
    "now=datetime.utcnow().strftime('%Y$m$d%H%M%S')\n",
    "root_logdir = 'tf_logs1'\n",
    "logdir = '{}/run-{}'.format(root_logdir,now)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "\n",
    "learning_rate = 0.005\n",
    "training_epochs = 2000\n",
    "batch_size = 100\n",
    "display_step=100\n",
    "\n",
    "#network pramenters\n",
    "\n",
    "n_hidden_1 = 40\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 120\n",
    "n_hidden_4 = 100\n",
    "n_hidden_5 = 10\n",
    "n_inputs = 25\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((5000, 2), 7763)\n"
     ]
    }
   ],
   "source": [
    "trainx,testx,trainy,testy,length = getdata()\n",
    "print (trainy.shape, length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_inputs], name=\"X\")\n",
    "y = tf.placeholder(\"int64\",[None,n_classes], name = 'Y') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2/np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs,n_neurons),stddev=stddev)\n",
    "        W = tf.Variable(init, name='Weights')\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name='Biases')\n",
    "        z = tf.matmul(X,W)+b\n",
    "        if activation == 'relu':\n",
    "            return tf.nn.relu(z)\n",
    "        elif activation == 'sig':\n",
    "            return tf.nn.sigmoid(z)\n",
    "        else:\n",
    "            return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('DNN'):\n",
    "    hidden1 = neuron_layer(x,n_hidden_1, 'Hidden1', activation='relu')\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden_2, 'Hidden2', activation='relu')\n",
    "    hidden3 = neuron_layer(hidden2, n_hidden_3, 'Hidden3', activation='relu')\n",
    "    hidden4 = neuron_layer(hidden2, n_hidden_3, 'Hidden4', activation='relu')\n",
    "    hidden5 = neuron_layer(hidden2, n_hidden_3, 'Hidden5', activation='sig')\n",
    "    logits = neuron_layer(hidden3, n_classes,'outputs', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Loss'):\n",
    "    xentropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits = logits)\n",
    "    loss = tf.reduce_mean(xentropy, name='Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Train'):\n",
    "    optimizer = tf.train.AdadeltaOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Eval'):\n",
    "    correct = tf.equal(tf.argmax(logits,1),tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "#saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'Train Accuracy: ', 0.49000001, 'Test Accuracy: ', 0.53674543)\n",
      "(8, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.53674543)\n",
      "(16, 'Train Accuracy: ', 0.30000001, 'Test Accuracy: ', 0.53674543)\n",
      "(24, 'Train Accuracy: ', 0.55000001, 'Test Accuracy: ', 0.53674543)\n",
      "(32, 'Train Accuracy: ', 0.54000002, 'Test Accuracy: ', 0.53674543)\n",
      "(40, 'Train Accuracy: ', 0.57999998, 'Test Accuracy: ', 0.53674543)\n",
      "(48, 'Train Accuracy: ', 0.46000001, 'Test Accuracy: ', 0.53674543)\n",
      "(56, 'Train Accuracy: ', 0.57999998, 'Test Accuracy: ', 0.53674543)\n",
      "(64, 'Train Accuracy: ', 0.54000002, 'Test Accuracy: ', 0.53674543)\n",
      "(72, 'Train Accuracy: ', 0.58999997, 'Test Accuracy: ', 0.53674543)\n",
      "(80, 'Train Accuracy: ', 0.50999999, 'Test Accuracy: ', 0.53674543)\n",
      "(88, 'Train Accuracy: ', 0.49000001, 'Test Accuracy: ', 0.53674543)\n",
      "(96, 'Train Accuracy: ', 0.66000003, 'Test Accuracy: ', 0.53674543)\n",
      "(104, 'Train Accuracy: ', 0.61000001, 'Test Accuracy: ', 0.53674543)\n",
      "(112, 'Train Accuracy: ', 0.49000001, 'Test Accuracy: ', 0.53674543)\n",
      "(120, 'Train Accuracy: ', 0.47999999, 'Test Accuracy: ', 0.53674543)\n",
      "(128, 'Train Accuracy: ', 0.49000001, 'Test Accuracy: ', 0.53674543)\n",
      "(136, 'Train Accuracy: ', 0.43000001, 'Test Accuracy: ', 0.53674543)\n",
      "(144, 'Train Accuracy: ', 0.52999997, 'Test Accuracy: ', 0.53674543)\n",
      "(152, 'Train Accuracy: ', 0.40000001, 'Test Accuracy: ', 0.53674543)\n",
      "(160, 'Train Accuracy: ', 0.44999999, 'Test Accuracy: ', 0.53674543)\n",
      "(168, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.53412074)\n",
      "(176, 'Train Accuracy: ', 0.50999999, 'Test Accuracy: ', 0.53149605)\n",
      "(184, 'Train Accuracy: ', 0.56, 'Test Accuracy: ', 0.53018373)\n",
      "(192, 'Train Accuracy: ', 0.50999999, 'Test Accuracy: ', 0.51968503)\n",
      "(200, 'Train Accuracy: ', 0.46000001, 'Test Accuracy: ', 0.50918633)\n",
      "(208, 'Train Accuracy: ', 0.49000001, 'Test Accuracy: ', 0.50787401)\n",
      "(216, 'Train Accuracy: ', 0.61000001, 'Test Accuracy: ', 0.50524932)\n",
      "(224, 'Train Accuracy: ', 0.55000001, 'Test Accuracy: ', 0.50131232)\n",
      "(232, 'Train Accuracy: ', 0.44999999, 'Test Accuracy: ', 0.50131232)\n",
      "(240, 'Train Accuracy: ', 0.46000001, 'Test Accuracy: ', 0.5065617)\n",
      "(248, 'Train Accuracy: ', 0.47, 'Test Accuracy: ', 0.50524932)\n",
      "(256, 'Train Accuracy: ', 0.44999999, 'Test Accuracy: ', 0.50524932)\n",
      "(264, 'Train Accuracy: ', 0.44999999, 'Test Accuracy: ', 0.50787401)\n",
      "(272, 'Train Accuracy: ', 0.56999999, 'Test Accuracy: ', 0.50918633)\n",
      "(280, 'Train Accuracy: ', 0.49000001, 'Test Accuracy: ', 0.50262469)\n",
      "(288, 'Train Accuracy: ', 0.56999999, 'Test Accuracy: ', 0.5065617)\n",
      "(296, 'Train Accuracy: ', 0.56999999, 'Test Accuracy: ', 0.50918633)\n",
      "(304, 'Train Accuracy: ', 0.60000002, 'Test Accuracy: ', 0.5065617)\n",
      "(312, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.50918633)\n",
      "(320, 'Train Accuracy: ', 0.56999999, 'Test Accuracy: ', 0.50524932)\n",
      "(328, 'Train Accuracy: ', 0.47, 'Test Accuracy: ', 0.50524932)\n",
      "(336, 'Train Accuracy: ', 0.56999999, 'Test Accuracy: ', 0.5104987)\n",
      "(344, 'Train Accuracy: ', 0.51999998, 'Test Accuracy: ', 0.5065617)\n",
      "(352, 'Train Accuracy: ', 0.46000001, 'Test Accuracy: ', 0.50524932)\n",
      "(360, 'Train Accuracy: ', 0.49000001, 'Test Accuracy: ', 0.50787401)\n",
      "(368, 'Train Accuracy: ', 0.41999999, 'Test Accuracy: ', 0.51181102)\n",
      "(376, 'Train Accuracy: ', 0.50999999, 'Test Accuracy: ', 0.51181102)\n",
      "(384, 'Train Accuracy: ', 0.56999999, 'Test Accuracy: ', 0.5104987)\n",
      "(392, 'Train Accuracy: ', 0.50999999, 'Test Accuracy: ', 0.51312333)\n",
      "(400, 'Train Accuracy: ', 0.46000001, 'Test Accuracy: ', 0.51181102)\n",
      "(408, 'Train Accuracy: ', 0.50999999, 'Test Accuracy: ', 0.5104987)\n",
      "(416, 'Train Accuracy: ', 0.56999999, 'Test Accuracy: ', 0.5065617)\n",
      "(424, 'Train Accuracy: ', 0.52999997, 'Test Accuracy: ', 0.50524932)\n",
      "(432, 'Train Accuracy: ', 0.44999999, 'Test Accuracy: ', 0.50393701)\n",
      "(440, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.50262469)\n",
      "(448, 'Train Accuracy: ', 0.47999999, 'Test Accuracy: ', 0.49868765)\n",
      "(456, 'Train Accuracy: ', 0.44999999, 'Test Accuracy: ', 0.5)\n",
      "(464, 'Train Accuracy: ', 0.51999998, 'Test Accuracy: ', 0.49868765)\n",
      "(472, 'Train Accuracy: ', 0.52999997, 'Test Accuracy: ', 0.50131232)\n",
      "(480, 'Train Accuracy: ', 0.52999997, 'Test Accuracy: ', 0.50393701)\n",
      "(488, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.50131232)\n",
      "(496, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.5)\n",
      "(504, 'Train Accuracy: ', 0.50999999, 'Test Accuracy: ', 0.50524932)\n",
      "(512, 'Train Accuracy: ', 0.51999998, 'Test Accuracy: ', 0.50262469)\n",
      "(520, 'Train Accuracy: ', 0.56999999, 'Test Accuracy: ', 0.50393701)\n",
      "(528, 'Train Accuracy: ', 0.54000002, 'Test Accuracy: ', 0.5104987)\n",
      "(536, 'Train Accuracy: ', 0.56999999, 'Test Accuracy: ', 0.50262469)\n",
      "(544, 'Train Accuracy: ', 0.51999998, 'Test Accuracy: ', 0.5065617)\n",
      "(552, 'Train Accuracy: ', 0.41999999, 'Test Accuracy: ', 0.50393701)\n",
      "(560, 'Train Accuracy: ', 0.47, 'Test Accuracy: ', 0.50524932)\n",
      "(568, 'Train Accuracy: ', 0.41, 'Test Accuracy: ', 0.5065617)\n",
      "(576, 'Train Accuracy: ', 0.56999999, 'Test Accuracy: ', 0.50787401)\n",
      "(584, 'Train Accuracy: ', 0.57999998, 'Test Accuracy: ', 0.51181102)\n",
      "(592, 'Train Accuracy: ', 0.50999999, 'Test Accuracy: ', 0.50524932)\n",
      "(600, 'Train Accuracy: ', 0.44999999, 'Test Accuracy: ', 0.50787401)\n",
      "(608, 'Train Accuracy: ', 0.47999999, 'Test Accuracy: ', 0.51574802)\n",
      "(616, 'Train Accuracy: ', 0.61000001, 'Test Accuracy: ', 0.51443571)\n",
      "(624, 'Train Accuracy: ', 0.56999999, 'Test Accuracy: ', 0.51443571)\n",
      "(632, 'Train Accuracy: ', 0.43000001, 'Test Accuracy: ', 0.51181102)\n",
      "(640, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.51443571)\n",
      "(648, 'Train Accuracy: ', 0.46000001, 'Test Accuracy: ', 0.51443571)\n",
      "(656, 'Train Accuracy: ', 0.46000001, 'Test Accuracy: ', 0.50393701)\n",
      "(664, 'Train Accuracy: ', 0.51999998, 'Test Accuracy: ', 0.51181102)\n",
      "(672, 'Train Accuracy: ', 0.52999997, 'Test Accuracy: ', 0.5065617)\n",
      "(680, 'Train Accuracy: ', 0.52999997, 'Test Accuracy: ', 0.50131232)\n",
      "(688, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.5065617)\n",
      "(696, 'Train Accuracy: ', 0.47999999, 'Test Accuracy: ', 0.50393701)\n",
      "(704, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.50787401)\n",
      "(712, 'Train Accuracy: ', 0.52999997, 'Test Accuracy: ', 0.5065617)\n",
      "(720, 'Train Accuracy: ', 0.58999997, 'Test Accuracy: ', 0.50918633)\n",
      "(728, 'Train Accuracy: ', 0.50999999, 'Test Accuracy: ', 0.50393701)\n",
      "(736, 'Train Accuracy: ', 0.56, 'Test Accuracy: ', 0.51181102)\n",
      "(744, 'Train Accuracy: ', 0.51999998, 'Test Accuracy: ', 0.50918633)\n",
      "(752, 'Train Accuracy: ', 0.44999999, 'Test Accuracy: ', 0.49868765)\n",
      "(760, 'Train Accuracy: ', 0.41999999, 'Test Accuracy: ', 0.50524932)\n",
      "(768, 'Train Accuracy: ', 0.43000001, 'Test Accuracy: ', 0.50787401)\n",
      "(776, 'Train Accuracy: ', 0.56, 'Test Accuracy: ', 0.50524932)\n",
      "(784, 'Train Accuracy: ', 0.55000001, 'Test Accuracy: ', 0.50524932)\n",
      "(792, 'Train Accuracy: ', 0.50999999, 'Test Accuracy: ', 0.5065617)\n",
      "(800, 'Train Accuracy: ', 0.44999999, 'Test Accuracy: ', 0.50918633)\n",
      "(808, 'Train Accuracy: ', 0.46000001, 'Test Accuracy: ', 0.50524932)\n",
      "(816, 'Train Accuracy: ', 0.64999998, 'Test Accuracy: ', 0.5065617)\n",
      "(824, 'Train Accuracy: ', 0.52999997, 'Test Accuracy: ', 0.50918633)\n",
      "(832, 'Train Accuracy: ', 0.44999999, 'Test Accuracy: ', 0.50393701)\n",
      "(840, 'Train Accuracy: ', 0.50999999, 'Test Accuracy: ', 0.50787401)\n",
      "(848, 'Train Accuracy: ', 0.46000001, 'Test Accuracy: ', 0.50787401)\n",
      "(856, 'Train Accuracy: ', 0.44999999, 'Test Accuracy: ', 0.50787401)\n",
      "(864, 'Train Accuracy: ', 0.54000002, 'Test Accuracy: ', 0.50918633)\n",
      "(872, 'Train Accuracy: ', 0.52999997, 'Test Accuracy: ', 0.5104987)\n",
      "(880, 'Train Accuracy: ', 0.57999998, 'Test Accuracy: ', 0.50787401)\n",
      "(888, 'Train Accuracy: ', 0.52999997, 'Test Accuracy: ', 0.50787401)\n",
      "(896, 'Train Accuracy: ', 0.50999999, 'Test Accuracy: ', 0.5065617)\n",
      "(904, 'Train Accuracy: ', 0.47, 'Test Accuracy: ', 0.50393701)\n",
      "(912, 'Train Accuracy: ', 0.50999999, 'Test Accuracy: ', 0.50918633)\n",
      "(920, 'Train Accuracy: ', 0.57999998, 'Test Accuracy: ', 0.5104987)\n",
      "(928, 'Train Accuracy: ', 0.55000001, 'Test Accuracy: ', 0.50262469)\n",
      "(936, 'Train Accuracy: ', 0.55000001, 'Test Accuracy: ', 0.50918633)\n",
      "(944, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.51443571)\n",
      "(952, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.50262469)\n",
      "(960, 'Train Accuracy: ', 0.44, 'Test Accuracy: ', 0.51443571)\n",
      "(968, 'Train Accuracy: ', 0.47, 'Test Accuracy: ', 0.51181102)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(976, 'Train Accuracy: ', 0.55000001, 'Test Accuracy: ', 0.50918633)\n",
      "(984, 'Train Accuracy: ', 0.54000002, 'Test Accuracy: ', 0.5)\n",
      "(992, 'Train Accuracy: ', 0.50999999, 'Test Accuracy: ', 0.51181102)\n",
      "(1000, 'Train Accuracy: ', 0.41999999, 'Test Accuracy: ', 0.50393701)\n",
      "(1008, 'Train Accuracy: ', 0.44999999, 'Test Accuracy: ', 0.50524932)\n",
      "(1016, 'Train Accuracy: ', 0.63999999, 'Test Accuracy: ', 0.50918633)\n",
      "(1024, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.50918633)\n",
      "(1032, 'Train Accuracy: ', 0.41999999, 'Test Accuracy: ', 0.50393701)\n",
      "(1040, 'Train Accuracy: ', 0.56, 'Test Accuracy: ', 0.50918633)\n",
      "(1048, 'Train Accuracy: ', 0.43000001, 'Test Accuracy: ', 0.50918633)\n",
      "(1056, 'Train Accuracy: ', 0.41, 'Test Accuracy: ', 0.5065617)\n",
      "(1064, 'Train Accuracy: ', 0.57999998, 'Test Accuracy: ', 0.51181102)\n",
      "(1072, 'Train Accuracy: ', 0.52999997, 'Test Accuracy: ', 0.51574802)\n",
      "(1080, 'Train Accuracy: ', 0.55000001, 'Test Accuracy: ', 0.50262469)\n",
      "(1088, 'Train Accuracy: ', 0.55000001, 'Test Accuracy: ', 0.51181102)\n",
      "(1096, 'Train Accuracy: ', 0.54000002, 'Test Accuracy: ', 0.5104987)\n",
      "(1104, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.50524932)\n",
      "(1112, 'Train Accuracy: ', 0.52999997, 'Test Accuracy: ', 0.51443571)\n",
      "(1120, 'Train Accuracy: ', 0.55000001, 'Test Accuracy: ', 0.51706034)\n",
      "(1128, 'Train Accuracy: ', 0.56, 'Test Accuracy: ', 0.50524932)\n",
      "(1136, 'Train Accuracy: ', 0.55000001, 'Test Accuracy: ', 0.51312333)\n",
      "(1144, 'Train Accuracy: ', 0.50999999, 'Test Accuracy: ', 0.51181102)\n",
      "(1152, 'Train Accuracy: ', 0.47999999, 'Test Accuracy: ', 0.5065617)\n",
      "(1160, 'Train Accuracy: ', 0.47, 'Test Accuracy: ', 0.51312333)\n",
      "(1168, 'Train Accuracy: ', 0.43000001, 'Test Accuracy: ', 0.50787401)\n",
      "(1176, 'Train Accuracy: ', 0.56999999, 'Test Accuracy: ', 0.51312333)\n",
      "(1184, 'Train Accuracy: ', 0.54000002, 'Test Accuracy: ', 0.50918633)\n",
      "(1192, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.5104987)\n",
      "(1200, 'Train Accuracy: ', 0.41999999, 'Test Accuracy: ', 0.50918633)\n",
      "(1208, 'Train Accuracy: ', 0.44999999, 'Test Accuracy: ', 0.5065617)\n",
      "(1216, 'Train Accuracy: ', 0.68000001, 'Test Accuracy: ', 0.50787401)\n",
      "(1224, 'Train Accuracy: ', 0.49000001, 'Test Accuracy: ', 0.5104987)\n",
      "(1232, 'Train Accuracy: ', 0.41, 'Test Accuracy: ', 0.50262469)\n",
      "(1240, 'Train Accuracy: ', 0.55000001, 'Test Accuracy: ', 0.5104987)\n",
      "(1248, 'Train Accuracy: ', 0.41999999, 'Test Accuracy: ', 0.51443571)\n",
      "(1256, 'Train Accuracy: ', 0.40000001, 'Test Accuracy: ', 0.50262469)\n",
      "(1264, 'Train Accuracy: ', 0.56, 'Test Accuracy: ', 0.51574802)\n",
      "(1272, 'Train Accuracy: ', 0.50999999, 'Test Accuracy: ', 0.51706034)\n",
      "(1280, 'Train Accuracy: ', 0.56999999, 'Test Accuracy: ', 0.50918633)\n",
      "(1288, 'Train Accuracy: ', 0.54000002, 'Test Accuracy: ', 0.51312333)\n",
      "(1296, 'Train Accuracy: ', 0.54000002, 'Test Accuracy: ', 0.51181102)\n",
      "(1304, 'Train Accuracy: ', 0.54000002, 'Test Accuracy: ', 0.5065617)\n",
      "(1312, 'Train Accuracy: ', 0.56999999, 'Test Accuracy: ', 0.51443571)\n",
      "(1320, 'Train Accuracy: ', 0.54000002, 'Test Accuracy: ', 0.51181102)\n",
      "(1328, 'Train Accuracy: ', 0.54000002, 'Test Accuracy: ', 0.50393701)\n",
      "(1336, 'Train Accuracy: ', 0.52999997, 'Test Accuracy: ', 0.50918633)\n",
      "(1344, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.5065617)\n",
      "(1352, 'Train Accuracy: ', 0.47, 'Test Accuracy: ', 0.50393701)\n",
      "(1360, 'Train Accuracy: ', 0.46000001, 'Test Accuracy: ', 0.50393701)\n",
      "(1368, 'Train Accuracy: ', 0.46000001, 'Test Accuracy: ', 0.50918633)\n",
      "(1376, 'Train Accuracy: ', 0.57999998, 'Test Accuracy: ', 0.50918633)\n",
      "(1384, 'Train Accuracy: ', 0.54000002, 'Test Accuracy: ', 0.50262469)\n",
      "(1392, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.5065617)\n",
      "(1400, 'Train Accuracy: ', 0.41999999, 'Test Accuracy: ', 0.51181102)\n",
      "(1408, 'Train Accuracy: ', 0.44999999, 'Test Accuracy: ', 0.50262469)\n",
      "(1416, 'Train Accuracy: ', 0.69, 'Test Accuracy: ', 0.5104987)\n",
      "(1424, 'Train Accuracy: ', 0.46000001, 'Test Accuracy: ', 0.5104987)\n",
      "(1432, 'Train Accuracy: ', 0.41, 'Test Accuracy: ', 0.49475065)\n",
      "(1440, 'Train Accuracy: ', 0.55000001, 'Test Accuracy: ', 0.50787401)\n",
      "(1448, 'Train Accuracy: ', 0.43000001, 'Test Accuracy: ', 0.50918633)\n",
      "(1456, 'Train Accuracy: ', 0.40000001, 'Test Accuracy: ', 0.49606299)\n",
      "(1464, 'Train Accuracy: ', 0.58999997, 'Test Accuracy: ', 0.5104987)\n",
      "(1472, 'Train Accuracy: ', 0.49000001, 'Test Accuracy: ', 0.51181102)\n",
      "(1480, 'Train Accuracy: ', 0.54000002, 'Test Accuracy: ', 0.49475065)\n",
      "(1488, 'Train Accuracy: ', 0.57999998, 'Test Accuracy: ', 0.5065617)\n",
      "(1496, 'Train Accuracy: ', 0.55000001, 'Test Accuracy: ', 0.50787401)\n",
      "(1504, 'Train Accuracy: ', 0.55000001, 'Test Accuracy: ', 0.49737534)\n",
      "(1512, 'Train Accuracy: ', 0.58999997, 'Test Accuracy: ', 0.50787401)\n",
      "(1520, 'Train Accuracy: ', 0.51999998, 'Test Accuracy: ', 0.50393701)\n",
      "(1528, 'Train Accuracy: ', 0.56999999, 'Test Accuracy: ', 0.49868765)\n",
      "(1536, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.5)\n",
      "(1544, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.50524932)\n",
      "(1552, 'Train Accuracy: ', 0.44999999, 'Test Accuracy: ', 0.50393701)\n",
      "(1560, 'Train Accuracy: ', 0.47, 'Test Accuracy: ', 0.50262469)\n",
      "(1568, 'Train Accuracy: ', 0.46000001, 'Test Accuracy: ', 0.50131232)\n",
      "(1576, 'Train Accuracy: ', 0.56999999, 'Test Accuracy: ', 0.50393701)\n",
      "(1584, 'Train Accuracy: ', 0.54000002, 'Test Accuracy: ', 0.50262469)\n",
      "(1592, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.50262469)\n",
      "(1600, 'Train Accuracy: ', 0.41999999, 'Test Accuracy: ', 0.50262469)\n",
      "(1608, 'Train Accuracy: ', 0.47999999, 'Test Accuracy: ', 0.49737534)\n",
      "(1616, 'Train Accuracy: ', 0.69, 'Test Accuracy: ', 0.5)\n",
      "(1624, 'Train Accuracy: ', 0.47, 'Test Accuracy: ', 0.50131232)\n",
      "(1632, 'Train Accuracy: ', 0.41, 'Test Accuracy: ', 0.49737534)\n",
      "(1640, 'Train Accuracy: ', 0.55000001, 'Test Accuracy: ', 0.5)\n",
      "(1648, 'Train Accuracy: ', 0.43000001, 'Test Accuracy: ', 0.5)\n",
      "(1656, 'Train Accuracy: ', 0.38, 'Test Accuracy: ', 0.49868765)\n",
      "(1664, 'Train Accuracy: ', 0.58999997, 'Test Accuracy: ', 0.49868765)\n",
      "(1672, 'Train Accuracy: ', 0.50999999, 'Test Accuracy: ', 0.5)\n",
      "(1680, 'Train Accuracy: ', 0.56, 'Test Accuracy: ', 0.5)\n",
      "(1688, 'Train Accuracy: ', 0.62, 'Test Accuracy: ', 0.5)\n",
      "(1696, 'Train Accuracy: ', 0.56999999, 'Test Accuracy: ', 0.5)\n",
      "(1704, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.49606299)\n",
      "(1712, 'Train Accuracy: ', 0.61000001, 'Test Accuracy: ', 0.49868765)\n",
      "(1720, 'Train Accuracy: ', 0.56, 'Test Accuracy: ', 0.5)\n",
      "(1728, 'Train Accuracy: ', 0.56, 'Test Accuracy: ', 0.49737534)\n",
      "(1736, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.50131232)\n",
      "(1744, 'Train Accuracy: ', 0.5, 'Test Accuracy: ', 0.5)\n",
      "(1752, 'Train Accuracy: ', 0.46000001, 'Test Accuracy: ', 0.49606299)\n",
      "(1760, 'Train Accuracy: ', 0.49000001, 'Test Accuracy: ', 0.50262469)\n",
      "(1768, 'Train Accuracy: ', 0.46000001, 'Test Accuracy: ', 0.50262469)\n",
      "(1776, 'Train Accuracy: ', 0.56, 'Test Accuracy: ', 0.50524932)\n",
      "(1784, 'Train Accuracy: ', 0.51999998, 'Test Accuracy: ', 0.49737534)\n",
      "(1792, 'Train Accuracy: ', 0.47999999, 'Test Accuracy: ', 0.50131232)\n",
      "(1800, 'Train Accuracy: ', 0.41999999, 'Test Accuracy: ', 0.50262469)\n",
      "(1808, 'Train Accuracy: ', 0.49000001, 'Test Accuracy: ', 0.5)\n",
      "(1816, 'Train Accuracy: ', 0.68000001, 'Test Accuracy: ', 0.50524932)\n",
      "(1824, 'Train Accuracy: ', 0.47, 'Test Accuracy: ', 0.50393701)\n",
      "(1832, 'Train Accuracy: ', 0.40000001, 'Test Accuracy: ', 0.49606299)\n",
      "(1840, 'Train Accuracy: ', 0.52999997, 'Test Accuracy: ', 0.50262469)\n",
      "(1848, 'Train Accuracy: ', 0.44999999, 'Test Accuracy: ', 0.49868765)\n",
      "(1856, 'Train Accuracy: ', 0.41, 'Test Accuracy: ', 0.49606299)\n",
      "(1864, 'Train Accuracy: ', 0.60000002, 'Test Accuracy: ', 0.5)\n",
      "(1872, 'Train Accuracy: ', 0.52999997, 'Test Accuracy: ', 0.5)\n",
      "(1880, 'Train Accuracy: ', 0.52999997, 'Test Accuracy: ', 0.49212599)\n",
      "(1888, 'Train Accuracy: ', 0.66000003, 'Test Accuracy: ', 0.50262469)\n",
      "(1896, 'Train Accuracy: ', 0.55000001, 'Test Accuracy: ', 0.50131232)\n",
      "(1904, 'Train Accuracy: ', 0.51999998, 'Test Accuracy: ', 0.49212599)\n",
      "(1912, 'Train Accuracy: ', 0.62, 'Test Accuracy: ', 0.49737534)\n",
      "(1920, 'Train Accuracy: ', 0.56, 'Test Accuracy: ', 0.49737534)\n",
      "(1928, 'Train Accuracy: ', 0.56999999, 'Test Accuracy: ', 0.4895013)\n",
      "(1936, 'Train Accuracy: ', 0.47999999, 'Test Accuracy: ', 0.49868765)\n",
      "(1944, 'Train Accuracy: ', 0.52999997, 'Test Accuracy: ', 0.49081364)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1952, 'Train Accuracy: ', 0.47, 'Test Accuracy: ', 0.48818898)\n",
      "(1960, 'Train Accuracy: ', 0.47999999, 'Test Accuracy: ', 0.5)\n",
      "(1968, 'Train Accuracy: ', 0.49000001, 'Test Accuracy: ', 0.49475065)\n",
      "(1976, 'Train Accuracy: ', 0.56, 'Test Accuracy: ', 0.49606299)\n",
      "(1984, 'Train Accuracy: ', 0.52999997, 'Test Accuracy: ', 0.49343833)\n",
      "(1992, 'Train Accuracy: ', 0.47, 'Test Accuracy: ', 0.50393701)\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: Batchdata/batch/fifo_queue_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_DOUBLE, DT_INT8], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Batchdata/batch/fifo_queue, Batchdata/batch/Const, Batchdata/batch/Const_1)]]\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('Batchdata'):\n",
    "    x_bat, y_bat = tf.train.batch([trainx,trainy],enqueue_many=True,\n",
    "                    batch_size=batch_size, capacity=8000)\n",
    "\n",
    "loss_summary = tf.summary.scalar('Loss', loss)\n",
    "file_writer = tf.summary.FileWriter(logdir,tf.get_default_graph())\n",
    "# Training of the Model\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "    for epoch in range(training_epochs):\n",
    "        for iteration in range(length/batch_size):\n",
    "            x_batch, y_batch = sess.run([x_bat,y_bat])\n",
    "            if iteration %10 ==0:\n",
    "                summary_str= loss_summary.eval(feed_dict={x: x_batch,y:y_batch})\n",
    "                step = epoch * int(length/batch_size)+iteration\n",
    "                file_writer.add_summary(summary_str,step)\n",
    "            #y_batch = y_batch.reshape([2,])\n",
    "            #print y_batch\n",
    "            sess.run(training_op, feed_dict = {x: x_batch,y:y_batch})\n",
    "            \n",
    "        acc_train = accuracy.eval(feed_dict = {x: x_batch,y:y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict = {x: testx,y:testy})\n",
    "        \n",
    "        if epoch%8 == 0:\n",
    "            print(epoch, 'Train Accuracy: ', acc_train, 'Test Accuracy: ',acc_test)\n",
    "    \n",
    "    #save_path=saver.save(sess,'my_model_.ckpt')\n",
    "    file_writer.close()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_preceptron(x,weighrs,biases):\n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "\n",
    "    layer_3 = tf.add(tf.matmul(layer_2,weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.sigmoid(layer_3)\n",
    "\n",
    "    \n",
    "    out_layer = tf.matmul(layer_3, weights['out'])+ biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1' : tf.Variable(tf.random_normal([n_inputs,n_hidden_1])),\n",
    "    'h2' : tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n",
    "    'h3' : tf.Variable(tf.random_normal([n_hidden_2,n_hidden_3])),\n",
    "    'out' : tf.Variable(tf.random_normal([n_hidden_3,n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1' : tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2' : tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'b3' : tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    'out' : tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = multilayer_preceptron(x,weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y))\n",
    "optimizer = tf.train.AdadeltaOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 2/2000 [00:00<02:36, 12.73it/s]\u001b[A\n",
      "  0%|          | 4/2000 [00:00<02:32, 13.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', '0001', 'cost=', 'nan')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  0%|          | 6/2000 [00:00<02:31, 13.15it/s]\u001b[A\n",
      "  0%|          | 8/2000 [00:00<02:27, 13.50it/s]\u001b[A\n",
      "  0%|          | 10/2000 [00:00<02:22, 13.95it/s]\u001b[A\n",
      "  1%|          | 12/2000 [00:00<02:20, 14.14it/s]\u001b[A\n",
      "  1%|          | 14/2000 [00:01<02:21, 13.99it/s]\u001b[A\n",
      "  1%|          | 16/2000 [00:01<02:17, 14.45it/s]\u001b[A\n",
      "  1%|          | 18/2000 [00:01<02:16, 14.49it/s]\u001b[A\n",
      "  1%|          | 20/2000 [00:01<02:14, 14.69it/s]\u001b[A\n",
      "  1%|          | 22/2000 [00:01<02:15, 14.57it/s]\u001b[A\n",
      "  1%|          | 24/2000 [00:01<02:17, 14.39it/s]\u001b[A\n",
      "  1%|▏         | 26/2000 [00:01<02:16, 14.49it/s]\u001b[A\n",
      "  1%|▏         | 28/2000 [00:01<02:20, 14.07it/s]\u001b[A\n",
      "  2%|▏         | 30/2000 [00:02<02:18, 14.20it/s]\u001b[A\n",
      "  2%|▏         | 32/2000 [00:02<02:18, 14.26it/s]\u001b[A\n",
      "  2%|▏         | 34/2000 [00:02<02:18, 14.24it/s]\u001b[A\n",
      "  2%|▏         | 36/2000 [00:02<02:18, 14.18it/s]\u001b[A\n",
      "  2%|▏         | 38/2000 [00:02<02:17, 14.31it/s]\u001b[A\n",
      "  2%|▏         | 40/2000 [00:02<02:38, 12.33it/s]\u001b[A\n",
      "  2%|▏         | 42/2000 [00:03<03:28,  9.40it/s]\u001b[A\n",
      "  2%|▏         | 44/2000 [00:03<03:08, 10.39it/s]\u001b[A\n",
      "  2%|▏         | 46/2000 [00:03<02:49, 11.53it/s]\u001b[A\n",
      "  2%|▏         | 48/2000 [00:03<02:36, 12.44it/s]\u001b[A\n",
      "  2%|▎         | 50/2000 [00:03<02:28, 13.12it/s]\u001b[A\n",
      "  3%|▎         | 52/2000 [00:03<02:22, 13.65it/s]\u001b[A\n",
      "  3%|▎         | 54/2000 [00:04<02:20, 13.86it/s]\u001b[A\n",
      "  3%|▎         | 56/2000 [00:04<02:16, 14.29it/s]\u001b[A\n",
      "  3%|▎         | 58/2000 [00:04<02:13, 14.55it/s]\u001b[A\n",
      "  3%|▎         | 60/2000 [00:04<02:10, 14.81it/s]\u001b[A\n",
      "  3%|▎         | 62/2000 [00:04<02:12, 14.66it/s]\u001b[A\n",
      "  3%|▎         | 64/2000 [00:04<02:12, 14.66it/s]\u001b[A\n",
      "  3%|▎         | 66/2000 [00:04<02:12, 14.55it/s]\u001b[A\n",
      "  3%|▎         | 68/2000 [00:04<02:17, 14.03it/s]\u001b[A\n",
      "  4%|▎         | 70/2000 [00:05<02:14, 14.37it/s]\u001b[A\n",
      "  4%|▎         | 72/2000 [00:05<02:14, 14.38it/s]\u001b[A\n",
      "  4%|▎         | 74/2000 [00:05<02:13, 14.43it/s]\u001b[A\n",
      "  4%|▍         | 76/2000 [00:05<02:29, 12.89it/s]\u001b[A\n",
      "  4%|▍         | 78/2000 [00:05<02:59, 10.73it/s]\u001b[A\n",
      "  4%|▍         | 80/2000 [00:06<03:01, 10.56it/s]\u001b[A\n",
      "  4%|▍         | 82/2000 [00:06<02:45, 11.56it/s]\u001b[A\n",
      "  4%|▍         | 84/2000 [00:06<02:37, 12.17it/s]\u001b[A\n",
      "  4%|▍         | 86/2000 [00:06<02:28, 12.89it/s]\u001b[A\n",
      "  4%|▍         | 88/2000 [00:06<02:21, 13.49it/s]\u001b[A\n",
      "  4%|▍         | 90/2000 [00:06<02:16, 14.03it/s]\u001b[A\n",
      "  5%|▍         | 92/2000 [00:06<02:13, 14.32it/s]\u001b[A\n",
      "  5%|▍         | 94/2000 [00:06<02:14, 14.17it/s]\u001b[A\n",
      "  5%|▍         | 96/2000 [00:07<02:12, 14.34it/s]\u001b[A\n",
      "  5%|▍         | 98/2000 [00:07<02:11, 14.49it/s]\u001b[A\n",
      "  5%|▌         | 100/2000 [00:07<02:29, 12.75it/s]\u001b[A\n",
      "  5%|▌         | 102/2000 [00:07<02:57, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', '0101', 'cost=', 'nan')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  5%|▌         | 104/2000 [00:07<02:59, 10.54it/s]\u001b[A\n",
      "  5%|▌         | 106/2000 [00:08<02:52, 11.00it/s]\u001b[A\n",
      "  5%|▌         | 108/2000 [00:08<03:06, 10.12it/s]\u001b[A\n",
      "  6%|▌         | 110/2000 [00:08<03:16,  9.64it/s]\u001b[A\n",
      "  6%|▌         | 112/2000 [00:08<02:52, 10.97it/s]\u001b[A\n",
      "\n",
      "  6%|▌         | 114/2000 [00:08<02:37, 11.94it/s]\u001b[A\n",
      "  6%|▌         | 116/2000 [00:09<02:52, 10.89it/s]\u001b[A\n",
      "  6%|▌         | 118/2000 [00:09<02:39, 11.78it/s]\u001b[A\n",
      "  6%|▌         | 120/2000 [00:09<02:29, 12.62it/s]\u001b[A\n",
      "  6%|▌         | 122/2000 [00:09<02:23, 13.12it/s]\u001b[A\n",
      "  6%|▌         | 124/2000 [00:09<02:17, 13.68it/s]\u001b[A\n",
      "  6%|▋         | 126/2000 [00:09<02:14, 13.94it/s]\u001b[A\n",
      "  6%|▋         | 128/2000 [00:09<02:12, 14.17it/s]\u001b[A\n",
      "  6%|▋         | 130/2000 [00:09<02:11, 14.18it/s]\u001b[A\n",
      "  7%|▋         | 132/2000 [00:10<02:12, 14.11it/s]\u001b[A\n",
      "  7%|▋         | 134/2000 [00:10<02:09, 14.37it/s]\u001b[A\n",
      "  7%|▋         | 136/2000 [00:10<02:08, 14.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: batch/fifo_queue_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_DOUBLE, DT_INT8], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, batch/Const, batch/Const_1)]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-626-848d4f1740d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             _, c = sess.run([optimizer,cost],feed_dict={x: batch_xs,\n\u001b[0;32m---> 21\u001b[0;31m                                                       y: batch_ys})\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;31m#compute avg loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mavg_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal_batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/patrick/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/patrick/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/patrick/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/patrick/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/patrick/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1116\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/patrick/anaconda2/lib/python2.7/contextlib.pyc\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/patrick/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.pyc\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewStatus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32myield\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "imageBatch, labelBatch = tf.train.batch([trainx,trainy],enqueue_many=True,\n",
    "                                        batch_size=batch_size, capacity=8000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "    \n",
    "    #training is done HERE\n",
    "    for epoch in tqdm(range(training_epochs)):\n",
    "        batch_xs, batch_ys = sess.run([imageBatch,labelBatch])\n",
    "        avg_cost = 0.\n",
    "        total_batches = int(length/batch_size)\n",
    "        #loop throough batches\n",
    "        for i in range(total_batches):\n",
    "            _, c = sess.run([optimizer,cost],feed_dict={x: batch_xs,\n",
    "                                                      y: batch_ys})\n",
    "            #compute avg loss\n",
    "            avg_cost += c/total_batches\n",
    "            \n",
    "        #display the logs\n",
    "        if epoch% display_step == 0:\n",
    "            print('Epoch:', '%04d'%(epoch+1), 'cost=', '{:.9f}'.format(avg_cost))\n",
    "    print('Optimization Complete!')\n",
    "    \n",
    "    #Test Model \n",
    "    correct_prediction = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "    #calculate Accurarcy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: testx, y: testy}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 69% accuracy for DOGE\n",
    "\n",
    "#parameters\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10000\n",
    "batch_size = 42\n",
    "display_step=100\n",
    "\n",
    "#network pramenters\n",
    "\n",
    "n_hidden_1 = 250\n",
    "n_hidden_2 = 500\n",
    "n_hidden_3 = 250\n",
    "n_inputs = 25\n",
    "n_classes = 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
